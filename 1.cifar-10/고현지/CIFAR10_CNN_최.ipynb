{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10-CNN_최.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0rP0ENdP1wP"
      },
      "source": [
        "import torch\n",
        "import torchvision # 데이터셋 불러오는 패키지\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWmal4ygg-v0",
        "outputId": "daecd3c9-0890-4857-8669-e8b4f0e45046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#이걸 안하면 train에 overfitting 되는 느낌\n",
        "transform_train = transforms.Compose([\n",
        "                                      # transforms.RandomRotation(10),\n",
        "                                      # transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
        "                                      # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                                      transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                     ])\n",
        "                                     \n",
        "\n",
        "# tensor로 바꿔주고, [-1,1]사이로 정규화 시킴\n",
        "transform_test = transforms.Compose( [transforms.ToTensor(), \n",
        "                             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# trainset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
        "\n",
        "# test \n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC-lHSJaQsfF",
        "outputId": "0e5d04f5-7cb1-49da-a4df-cfbbed12759a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(trainset.classes)\n",
        "print(trainset.__getitem__(1))\n",
        "print(len(trainset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "(tensor([[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         ...,\n",
            "         [ 0.3098,  0.1608, -0.2000,  ..., -0.5137, -0.5608, -0.3098],\n",
            "         [ 0.3647,  0.1059, -0.6549,  ..., -0.1922, -0.2549, -0.0275],\n",
            "         [ 0.2863,  0.1059, -0.0980,  ..., -0.3961, -0.4667, -0.2627]],\n",
            "\n",
            "        [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         ...,\n",
            "         [ 0.2471,  0.1373, -0.1843,  ..., -0.4745, -0.5294, -0.2941],\n",
            "         [ 0.2863,  0.0745, -0.6392,  ..., -0.1529, -0.2314, -0.0353],\n",
            "         [ 0.2157,  0.0902, -0.0667,  ..., -0.3961, -0.4824, -0.3098]],\n",
            "\n",
            "        [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         ...,\n",
            "         [ 0.3490,  0.3020, -0.0353,  ..., -0.3333, -0.3804, -0.1608],\n",
            "         [ 0.3333,  0.1765, -0.5608,  ..., -0.0353, -0.1294,  0.0431],\n",
            "         [ 0.2549,  0.1922,  0.0353,  ..., -0.3412, -0.4275, -0.2627]]]), 9)\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvK1j0A0fqA6",
        "outputId": "f3cba9e2-5a56-476f-d15b-5c78187ca64b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNN, self).__init__()\n",
        "        # 3 : input channel size  /  48 : output volume size(48개의 filter => ouput의 depth가 될 것), \n",
        "        # 3 : kernel(filter) size (3*3)  /  padding = 1 : padding size  /  stride = 1로 default\n",
        "\n",
        "        # common settings : F = 3, S = 1, P =1 / F = 5, S = 1, P = 2 / F = 5, S = 2, P = ? \n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=48, kernel_size=(3,3), padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=(3,3), padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(in_channels=96, out_channels=192, kernel_size=(3,3), padding=(1,1))\n",
        "        self.conv4 = nn.Conv2d(in_channels=192, out_channels=256, kernel_size=(3,3), padding=(1,1))\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.fc1 = nn.Linear(in_features=8*8*256, out_features=512)\n",
        "        self.fc2 = nn.Linear(in_features=512, out_features=64)\n",
        "        self.Dropout = nn.Dropout(0.25)\n",
        "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "    def forward(self, x):         # output 크기\n",
        "        x = F.relu(self.conv1(x)) # 32 x 32 x 48 > outputsize = (input size - filter size + 2*padding size)/stride + 1 = 32 \n",
        "        x = F.relu(self.conv2(x)) # 32 x 32 x 96\n",
        "        x = self.pool(x) # 16 x 16 x 96\n",
        "        x = self.Dropout(x)\n",
        "        x = F.relu(self.conv3(x)) # 16 x 16 x 192\n",
        "        x = F.relu(self.conv4(x)) # 16 x 16 x 256\n",
        "        x = self.pool(x) # 8 x 8 x 256\n",
        "        x = self.Dropout(x)\n",
        "        x = x.view(-1, 8*8*256) # reshape\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.Dropout(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "cvnn = ConvNN()\n",
        "cvnn.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNN(\n",
              "  (conv1): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=16384, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
              "  (Dropout): Dropout(p=0.25, inplace=False)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROYjtV9pR_dG"
      },
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cvnn.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNwEgGUO_gYB",
        "outputId": "6a126a09-7a2b-4eaa-f983-fb11a7b24e38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "epochs = 30 \n",
        "curr_lr = learning_rate\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  tot_loss = 0.0\n",
        "  correct = 0\n",
        "\n",
        "  for i, data in enumerate(trainloader, 0) : \n",
        "\n",
        "    images, labels = data # batch size만큼 가져올 것\n",
        "    images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
        "\n",
        "    outputs = cvnn(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tot_loss += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct += torch.sum(predicted == labels.data)\n",
        "        \n",
        "  if (epoch+1) % 20 == 0:\n",
        "        curr_lr /= 3\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = curr_lr\n",
        "\n",
        "\n",
        "  epoch_loss = tot_loss / len(trainloader)\n",
        "  epoch_acc = correct.float() / len(trainloader)\n",
        "  \n",
        "  print(\"===================================================\")\n",
        "  print(\"epoch: \", epoch + 1)\n",
        "  print(\"train loss: {:.5f}, acc: {:5f}\".format(epoch_loss, epoch_acc))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===================================================\n",
            "epoch:  1\n",
            "train loss: 1.72632, acc: 35.536003\n",
            "===================================================\n",
            "epoch:  2\n",
            "train loss: 1.29686, acc: 52.868004\n",
            "===================================================\n",
            "epoch:  3\n",
            "train loss: 1.09209, acc: 61.274002\n",
            "===================================================\n",
            "epoch:  4\n",
            "train loss: 0.94890, acc: 66.602005\n",
            "===================================================\n",
            "epoch:  5\n",
            "train loss: 0.87283, acc: 69.854004\n",
            "===================================================\n",
            "epoch:  6\n",
            "train loss: 0.80802, acc: 71.966003\n",
            "===================================================\n",
            "epoch:  7\n",
            "train loss: 0.76861, acc: 73.422005\n",
            "===================================================\n",
            "epoch:  8\n",
            "train loss: 0.72654, acc: 75.192001\n",
            "===================================================\n",
            "epoch:  9\n",
            "train loss: 0.68925, acc: 76.194000\n",
            "===================================================\n",
            "epoch:  10\n",
            "train loss: 0.67133, acc: 77.192001\n",
            "===================================================\n",
            "epoch:  11\n",
            "train loss: 0.64231, acc: 78.096001\n",
            "===================================================\n",
            "epoch:  12\n",
            "train loss: 0.62059, acc: 78.792007\n",
            "===================================================\n",
            "epoch:  13\n",
            "train loss: 0.60662, acc: 79.446007\n",
            "===================================================\n",
            "epoch:  14\n",
            "train loss: 0.58408, acc: 80.030006\n",
            "===================================================\n",
            "epoch:  15\n",
            "train loss: 0.57223, acc: 80.654007\n",
            "===================================================\n",
            "epoch:  16\n",
            "train loss: 0.55960, acc: 80.858002\n",
            "===================================================\n",
            "epoch:  17\n",
            "train loss: 0.55212, acc: 81.108002\n",
            "===================================================\n",
            "epoch:  18\n",
            "train loss: 0.52769, acc: 82.108002\n",
            "===================================================\n",
            "epoch:  19\n",
            "train loss: 0.52313, acc: 82.078003\n",
            "===================================================\n",
            "epoch:  20\n",
            "train loss: 0.50912, acc: 82.604004\n",
            "===================================================\n",
            "epoch:  21\n",
            "train loss: 0.44332, acc: 84.972008\n",
            "===================================================\n",
            "epoch:  22\n",
            "train loss: 0.42807, acc: 85.354004\n",
            "===================================================\n",
            "epoch:  23\n",
            "train loss: 0.42219, acc: 85.540001\n",
            "===================================================\n",
            "epoch:  24\n",
            "train loss: 0.41116, acc: 85.880005\n",
            "===================================================\n",
            "epoch:  25\n",
            "train loss: 0.40192, acc: 86.100006\n",
            "===================================================\n",
            "epoch:  26\n",
            "train loss: 0.39562, acc: 86.452003\n",
            "===================================================\n",
            "epoch:  27\n",
            "train loss: 0.39626, acc: 86.414001\n",
            "===================================================\n",
            "epoch:  28\n",
            "train loss: 0.38401, acc: 86.734001\n",
            "===================================================\n",
            "epoch:  29\n",
            "train loss: 0.38267, acc: 87.010002\n",
            "===================================================\n",
            "epoch:  30\n",
            "train loss: 0.37939, acc: 86.932007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW7_OlkXs_Zn",
        "outputId": "c27e4176-4790-4470-aa27-ae04158f6aae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cvnn.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "\n",
        "        images, labels = Variable(images).cuda(), labels.cuda()\n",
        "\n",
        "        outputs = cvnn(images)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of Test: {} %'.format(100 * correct / total))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Test: 86.25 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
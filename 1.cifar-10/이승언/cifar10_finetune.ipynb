{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_finetune",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W-ByjpiFR4H"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import ZeroPadding2D\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터셋 생성하기(정규화)\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# 원-핫 인코딩\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFP1fWp1FpDv"
      },
      "source": [
        "#conv_base=tf.keras.applications.ResNet50(weights='imagenet',include_top=False)\n",
        "from keras.applications import VGG19\n",
        "conv_base = VGG19(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep5K1jUeGEsf",
        "outputId": "ac46f4cb-a36b-425d-a145-fb7b3c2610bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6Xcj_P2_NCz"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
        "\n",
        "model_1= Sequential()\n",
        "model_1.add(conv_base) #Adds the base model (in this case vgg19 to model_1)\n",
        "model_1.add(Flatten()) \n",
        "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dropout(0.25))\n",
        "model_1.add(Dense(512,activation=('relu'))) \n",
        "model_1.add(Dropout(0.25))\n",
        "model_1.add(Dense(256,activation=('relu'))) \n",
        "#model_1.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
        "model_1.add(Dense(128,activation=('relu')))\n",
        "#model_1.add(Dropout(.2))\n",
        "model_1.add(Dense(10,activation=('softmax')))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvYmMm5k_eGj"
      },
      "source": [
        "from keras.optimizers import SGD,Adam\n",
        "learn_rate=.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model_1.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbhURq_THJ6E"
      },
      "source": [
        "conv_base.trainable = True"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uBEzC2LHMSd",
        "outputId": "deab5332-ae5f-4bac-d67d-b3f7e3cec49b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block4_conv1':\n",
        "        print(\"right\")  \n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "right\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfAn9zZrHVFT",
        "outputId": "06a669bf-86ad-411c-f12b-984fb5cbe956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history= model_1.fit(x_train, y_train, epochs = 40, batch_size = 100, validation_data = (x_valid, y_valid))\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "  2/450 [..............................] - ETA: 13s - loss: 2.3155 - accuracy: 0.1050WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_train_batch_end` time: 0.0504s). Check your callbacks.\n",
            "450/450 [==============================] - ETA: 0s - loss: 1.4264 - accuracy: 0.4855WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0122s). Check your callbacks.\n",
            "450/450 [==============================] - 28s 63ms/step - loss: 1.4264 - accuracy: 0.4855 - val_loss: 0.8776 - val_accuracy: 0.6950\n",
            "Epoch 2/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.8091 - accuracy: 0.7252 - val_loss: 0.6987 - val_accuracy: 0.7644\n",
            "Epoch 3/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 0.6579 - accuracy: 0.7770 - val_loss: 0.5982 - val_accuracy: 0.7984\n",
            "Epoch 4/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.5574 - accuracy: 0.8121 - val_loss: 0.5835 - val_accuracy: 0.8040\n",
            "Epoch 5/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.4886 - accuracy: 0.8334 - val_loss: 0.5379 - val_accuracy: 0.8152\n",
            "Epoch 6/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.4229 - accuracy: 0.8561 - val_loss: 0.5147 - val_accuracy: 0.8258\n",
            "Epoch 7/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.3654 - accuracy: 0.8756 - val_loss: 0.4572 - val_accuracy: 0.8480\n",
            "Epoch 8/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.3162 - accuracy: 0.8932 - val_loss: 0.4996 - val_accuracy: 0.8392\n",
            "Epoch 9/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.2686 - accuracy: 0.9084 - val_loss: 0.4616 - val_accuracy: 0.8548\n",
            "Epoch 10/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.2319 - accuracy: 0.9216 - val_loss: 0.4922 - val_accuracy: 0.8494\n",
            "Epoch 11/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.1942 - accuracy: 0.9352 - val_loss: 0.5507 - val_accuracy: 0.8420\n",
            "Epoch 12/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.1618 - accuracy: 0.9463 - val_loss: 0.4742 - val_accuracy: 0.8582\n",
            "Epoch 13/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.1353 - accuracy: 0.9545 - val_loss: 0.5137 - val_accuracy: 0.8544\n",
            "Epoch 14/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.1117 - accuracy: 0.9635 - val_loss: 0.5336 - val_accuracy: 0.8596\n",
            "Epoch 15/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0921 - accuracy: 0.9693 - val_loss: 0.5780 - val_accuracy: 0.8526\n",
            "Epoch 16/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0744 - accuracy: 0.9752 - val_loss: 0.6590 - val_accuracy: 0.8458\n",
            "Epoch 17/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0560 - accuracy: 0.9823 - val_loss: 0.6960 - val_accuracy: 0.8444\n",
            "Epoch 18/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0531 - accuracy: 0.9829 - val_loss: 0.6592 - val_accuracy: 0.8474\n",
            "Epoch 19/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0534 - accuracy: 0.9830 - val_loss: 0.6416 - val_accuracy: 0.8614\n",
            "Epoch 20/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.6866 - val_accuracy: 0.8576\n",
            "Epoch 21/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.6691 - val_accuracy: 0.8516\n",
            "Epoch 22/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 0.7149 - val_accuracy: 0.8468\n",
            "Epoch 23/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0292 - accuracy: 0.9914 - val_loss: 0.7087 - val_accuracy: 0.8624\n",
            "Epoch 24/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.7282 - val_accuracy: 0.8524\n",
            "Epoch 25/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0297 - accuracy: 0.9902 - val_loss: 0.7158 - val_accuracy: 0.8610\n",
            "Epoch 26/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.8001 - val_accuracy: 0.8546\n",
            "Epoch 27/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.7836 - val_accuracy: 0.8490\n",
            "Epoch 28/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.7376 - val_accuracy: 0.8622\n",
            "Epoch 29/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.7542 - val_accuracy: 0.8656\n",
            "Epoch 30/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.8537 - val_accuracy: 0.8474\n",
            "Epoch 31/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.7780 - val_accuracy: 0.8646\n",
            "Epoch 32/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.7718 - val_accuracy: 0.8646\n",
            "Epoch 33/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 4.6343e-04 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.8714\n",
            "Epoch 34/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 2.3348e-04 - accuracy: 1.0000 - val_loss: 0.8206 - val_accuracy: 0.8730\n",
            "Epoch 35/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 1.2097e-04 - accuracy: 1.0000 - val_loss: 0.8323 - val_accuracy: 0.8738\n",
            "Epoch 36/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 9.6027e-05 - accuracy: 1.0000 - val_loss: 0.8424 - val_accuracy: 0.8738\n",
            "Epoch 37/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 7.9313e-05 - accuracy: 1.0000 - val_loss: 0.8582 - val_accuracy: 0.8738\n",
            "Epoch 38/40\n",
            "450/450 [==============================] - 28s 61ms/step - loss: 6.6167e-05 - accuracy: 1.0000 - val_loss: 0.8672 - val_accuracy: 0.8746\n",
            "Epoch 39/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 6.3936e-05 - accuracy: 1.0000 - val_loss: 0.8735 - val_accuracy: 0.8734\n",
            "Epoch 40/40\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 5.5594e-05 - accuracy: 1.0000 - val_loss: 0.8830 - val_accuracy: 0.8734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvUh_dmzH_jJ",
        "outputId": "1f63a70b-fbe4-4634-a8c4-ab983f9fba21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print('## training loss ##')\n",
        "print(history.history['loss'])\n",
        "\n",
        "\n",
        "result = model_1.evaluate(x_test, y_test, batch_size=100)\n",
        "print('##  loss and accuracy ##')\n",
        "print(result)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## training loss ##\n",
            "[1.4264147281646729, 0.8091477155685425, 0.6578518152236938, 0.5574468970298767, 0.4886305034160614, 0.4229220151901245, 0.3653644025325775, 0.31619465351104736, 0.2686309814453125, 0.23194576799869537, 0.19415177404880524, 0.16180050373077393, 0.1352812796831131, 0.11173629760742188, 0.0921364352107048, 0.07443871349096298, 0.056015271693468094, 0.053058989346027374, 0.05338900908827782, 0.03812330216169357, 0.03889406844973564, 0.039090245962142944, 0.02917722426354885, 0.023007109761238098, 0.02968238666653633, 0.01784706488251686, 0.02592192403972149, 0.012253464199602604, 0.006347483489662409, 0.011432798579335213, 0.0188111774623394, 0.005072361323982477, 0.00046342608402483165, 0.0002334812597837299, 0.00012097381113562733, 9.602740465197712e-05, 7.931327127153054e-05, 6.616660539293662e-05, 6.393602961907163e-05, 5.559435885515995e-05]\n",
            "  1/100 [..............................] - ETA: 2s - loss: 1.6009 - accuracy: 0.8300WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0036s vs `on_test_batch_end` time: 0.0230s). Check your callbacks.\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.0602 - accuracy: 0.8609\n",
            "##  loss and accuracy ##\n",
            "[1.0601677894592285, 0.8608999848365784]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Ql0HJCM4b5",
        "outputId": "1cba7ab3-04c5-4f58-e920-2776af9c9285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# acc = history.history['acc']\n",
        "# val_acc = history.history['val_acc']\n",
        "# loss = history.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "\n",
        "# epochs = range(len(acc))\n",
        "\n",
        "# plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "# plt.title('Training and validation accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.figure()\n",
        "\n",
        "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "# plt.title('Training and validation loss')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-12a35bd861a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r899Hcgksst"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}